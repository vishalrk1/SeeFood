{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d986597-cc2e-402b-8b36-051e03758eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Vishal\n",
      " Volume Serial Number is 64D8-F0C2\n",
      "\n",
      " Directory of D:\\python\\ML\\Projects\\SEE FOOD\\data\n",
      "\n",
      "11/10/2021  11:44 AM    <DIR>          .\n",
      "11/10/2021  11:44 AM    <DIR>          ..\n",
      "21/09/2013  07:43 PM    <DIR>          apple_pie\n",
      "21/09/2013  07:43 PM    <DIR>          baby_back_ribs\n",
      "21/09/2013  07:43 PM    <DIR>          baklava\n",
      "21/09/2013  03:13 PM    <DIR>          beef_carpaccio\n",
      "21/09/2013  07:43 PM    <DIR>          beef_tartare\n",
      "21/09/2013  07:43 PM    <DIR>          beet_salad\n",
      "21/09/2013  02:51 PM    <DIR>          beignets\n",
      "21/09/2013  02:50 PM    <DIR>          bibimbap\n",
      "21/09/2013  07:43 PM    <DIR>          bread_pudding\n",
      "21/09/2013  03:20 PM    <DIR>          breakfast_burrito\n",
      "21/09/2013  07:43 PM    <DIR>          bruschetta\n",
      "21/09/2013  07:43 PM    <DIR>          caesar_salad\n",
      "21/09/2013  03:22 PM    <DIR>          cannoli\n",
      "21/09/2013  07:43 PM    <DIR>          caprese_salad\n",
      "21/09/2013  02:54 PM    <DIR>          carrot_cake\n",
      "09/07/2014  11:27 AM    <DIR>          ceviche\n",
      "21/09/2013  07:43 PM    <DIR>          cheese_plate\n",
      "21/09/2013  07:43 PM    <DIR>          cheesecake\n",
      "21/09/2013  07:43 PM    <DIR>          chicken_curry\n",
      "21/09/2013  07:43 PM    <DIR>          chicken_quesadilla\n",
      "21/09/2013  02:55 PM    <DIR>          chicken_wings\n",
      "21/09/2013  02:56 PM    <DIR>          chocolate_cake\n",
      "21/09/2013  07:43 PM    <DIR>          chocolate_mousse\n",
      "08/02/2014  01:02 PM    <DIR>          churros\n",
      "21/09/2013  03:12 PM    <DIR>          clam_chowder\n",
      "21/09/2013  02:53 PM    <DIR>          club_sandwich\n",
      "21/09/2013  02:51 PM    <DIR>          crab_cakes\n",
      "20/02/2014  07:49 PM    <DIR>          creme_brulee\n",
      "21/09/2013  03:12 PM    <DIR>          croque_madame\n",
      "21/09/2013  07:43 PM    <DIR>          cup_cakes\n",
      "21/09/2013  03:01 PM    <DIR>          deviled_eggs\n",
      "21/09/2013  03:13 PM    <DIR>          donuts\n",
      "21/09/2013  03:17 PM    <DIR>          dumplings\n",
      "21/09/2013  02:58 PM    <DIR>          edamame\n",
      "21/09/2013  07:43 PM    <DIR>          eggs_benedict\n",
      "21/09/2013  04:23 PM    <DIR>          escargots\n",
      "21/09/2013  02:54 PM    <DIR>          falafel\n",
      "21/09/2013  07:43 PM    <DIR>          filet_mignon\n",
      "21/09/2013  07:43 PM    <DIR>          fish_and_chips\n",
      "21/09/2013  02:48 PM    <DIR>          foie_gras\n",
      "21/09/2013  03:16 PM    <DIR>          french_fries\n",
      "21/09/2013  03:12 PM    <DIR>          french_onion_soup\n",
      "21/09/2013  07:43 PM    <DIR>          french_toast\n",
      "01/10/2013  07:45 PM    <DIR>          fried_calamari\n",
      "20/02/2014  03:15 PM    <DIR>          fried_rice\n",
      "21/09/2013  02:53 PM    <DIR>          frozen_yogurt\n",
      "21/09/2013  02:57 PM    <DIR>          garlic_bread\n",
      "21/09/2013  07:43 PM    <DIR>          gnocchi\n",
      "21/09/2013  02:48 PM    <DIR>          greek_salad\n",
      "21/09/2013  07:43 PM    <DIR>          grilled_cheese_sandwich\n",
      "21/09/2013  07:43 PM    <DIR>          grilled_salmon\n",
      "21/09/2013  03:03 PM    <DIR>          guacamole\n",
      "21/09/2013  07:43 PM    <DIR>          gyoza\n",
      "21/09/2013  07:43 PM    <DIR>          hamburger\n",
      "21/09/2013  03:23 PM    <DIR>          hot_and_sour_soup\n",
      "21/09/2013  07:43 PM    <DIR>          hot_dog\n",
      "21/09/2013  07:43 PM    <DIR>          huevos_rancheros\n",
      "21/09/2013  07:43 PM    <DIR>          hummus\n",
      "21/09/2013  03:24 PM    <DIR>          ice_cream\n",
      "10/10/2021  07:27 PM     5,132,666,035 images.zip\n",
      "01/10/2013  07:25 PM    <DIR>          lasagna\n",
      "21/09/2013  07:43 PM    <DIR>          lobster_bisque\n",
      "21/09/2013  03:25 PM    <DIR>          lobster_roll_sandwich\n",
      "21/09/2013  07:43 PM    <DIR>          macaroni_and_cheese\n",
      "21/09/2013  03:21 PM    <DIR>          macarons\n",
      "21/09/2013  07:43 PM    <DIR>          miso_soup\n",
      "21/09/2013  07:43 PM    <DIR>          mussels\n",
      "21/09/2013  03:26 PM    <DIR>          nachos\n",
      "21/09/2013  07:43 PM    <DIR>          omelette\n",
      "21/09/2013  07:43 PM    <DIR>          onion_rings\n",
      "21/09/2013  03:26 PM    <DIR>          oysters\n",
      "21/09/2013  02:49 PM    <DIR>          pad_thai\n",
      "21/09/2013  07:43 PM    <DIR>          paella\n",
      "21/09/2013  02:59 PM    <DIR>          pancakes\n",
      "21/09/2013  02:47 PM    <DIR>          panna_cotta\n",
      "21/09/2013  03:02 PM    <DIR>          peking_duck\n",
      "21/09/2013  03:25 PM    <DIR>          pho\n",
      "21/09/2013  03:22 PM    <DIR>          pizza\n",
      "21/09/2013  07:43 PM    <DIR>          pork_chop\n",
      "21/09/2013  07:43 PM    <DIR>          poutine\n",
      "21/09/2013  03:23 PM    <DIR>          prime_rib\n",
      "21/09/2013  02:50 PM    <DIR>          pulled_pork_sandwich\n",
      "21/09/2013  02:50 PM    <DIR>          ramen\n",
      "21/09/2013  03:14 PM    <DIR>          ravioli\n",
      "21/09/2013  03:00 PM    <DIR>          red_velvet_cake\n",
      "21/09/2013  02:51 PM    <DIR>          risotto\n",
      "21/09/2013  02:46 PM    <DIR>          samosa\n",
      "21/09/2013  02:46 PM    <DIR>          sashimi\n",
      "21/09/2013  02:58 PM    <DIR>          scallops\n",
      "21/09/2013  03:21 PM    <DIR>          seaweed_salad\n",
      "21/09/2013  03:17 PM    <DIR>          shrimp_and_grits\n",
      "21/09/2013  02:57 PM    <DIR>          spaghetti_bolognese\n",
      "21/09/2013  03:15 PM    <DIR>          spaghetti_carbonara\n",
      "21/09/2013  02:47 PM    <DIR>          spring_rolls\n",
      "21/09/2013  02:52 PM    <DIR>          steak\n",
      "21/09/2013  04:23 PM    <DIR>          strawberry_shortcake\n",
      "21/09/2013  03:18 PM    <DIR>          sushi\n",
      "21/09/2013  02:48 PM    <DIR>          tacos\n",
      "21/09/2013  03:20 PM    <DIR>          takoyaki\n",
      "21/09/2013  02:57 PM    <DIR>          tiramisu\n",
      "21/09/2013  03:18 PM    <DIR>          tuna_tartare\n",
      "21/09/2013  03:21 PM    <DIR>          waffles\n",
      "               1 File(s)  5,132,666,035 bytes\n",
      "             103 Dir(s)  32,004,210,688 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf4a4f7-db9b-449f-b851-91d6f2d046a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148428f6-ca51-408d-a150-dfd5d8ef7ed1",
   "metadata": {},
   "source": [
    "## Getting labels (in JSON form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef67732-7e68-4d69-a9fe-06e0533d59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "def get_labels(label_path):\n",
    "    with open(label_path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_labels = get_labels(\"meta/train.json\")\n",
    "test_labels = get_labels(\"meta/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95c479b-b089-4571-8e85-e9ac202a8bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels[\"churros\"]))\n",
    "print(len(test_labels[\"churros\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737afee-5940-442e-af16-83f1d4b00bf6",
   "metadata": {},
   "source": [
    "## Create target class folders and move images there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd7cbd65-bc6d-4a06-bfd1-08ba969002cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_images(parent_folder, new_subset, dataset, target_labels):\n",
    "    \"\"\"\n",
    "    Copies `labels[target_labels]` images from `parent_folder` to\n",
    "    `new_subset` (named after `dataset`) folder.\n",
    "    \n",
    "    E.g. move steak images to data/steak_subset/train/ & \n",
    "    data/steak_subset/test/\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    parent_folder (str) - original folder path with all data\n",
    "    new_subset (str) - name of parent folder to copy to\n",
    "    dataset (str) - which dataset? (train or test)\n",
    "    labels (list) - list of training or test labels\n",
    "    target_labels (list) - list of target labels to copy e.g. [\"steak\", \"pizza\"]\n",
    "    \"\"\"\n",
    "    # Get the appropriate labels\n",
    "    print(f\"\\nUsing {dataset} labels...\")\n",
    "    labels = get_labels(\"meta/\" + dataset + \".json\")\n",
    "    \n",
    "    # Loop through target labels\n",
    "    for i in target_labels:\n",
    "        # Make target directory\n",
    "        os.makedirs(parent_folder + \"/\" + new_subset + \"/\" + dataset + \"/\" + i, \n",
    "                    exist_ok=True)\n",
    "        \n",
    "        # Go through labels and get appropriate classes\n",
    "        images_moved = [] # Keep track of images moved\n",
    "        for j in labels[i]:\n",
    "            # Create original image path and new path\n",
    "            og_path = parent_folder + \"/\" + j + \".jpg\"\n",
    "            new_path = parent_folder + \"/\" + new_subset + \"/\" + dataset + \"/\" + j + \".jpg\"\n",
    "            \n",
    "            # Copy images from old path to new path\n",
    "            shutil.copy2(og_path, new_path)\n",
    "            images_moved.append(new_path)\n",
    "        print(f\"Copied {len(images_moved)} images from {dataset} dataset {i} class...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17a8f-c71d-4362-8f24-fb661babc02c",
   "metadata": {},
   "source": [
    "## Create function to get random sample of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7dab9b-152b-4834-ba04-a3aae8cd7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_images(target_dir, new_dir, sample_amount=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Get sample_amount percentage of random images from target_dir and copy them to new_dir.\n",
    "    \n",
    "    Preserves subdirectory file names.\n",
    "    \n",
    "    E.g. target_dir=pizza_steak/train/steak/all_files \n",
    "                -> new_dir_name/train/steak/X_percent_of_all_files\n",
    "                \n",
    "    Parameters\n",
    "    --------\n",
    "    target_dir (str) - file path of directory you want to extract images from\n",
    "    new_dir (str) - new directory path you want to copy original images to\n",
    "    sample_amount (float), default 0.1 - percentage of images to copy (e.g. 0.1 = 10%)\n",
    "    random_state (int), default 42 - random seed value \n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    # Get a list of dictionaries of image files in target_dir\n",
    "    # e.g. [{\"class_name\":[\"2348348.jpg\", \"2829119.jpg\"]}]\n",
    "    images = [{dir_name: os.listdir(target_dir + dir_name)} for dir_name in os.listdir(target_dir)]\n",
    "\n",
    "    for i in images:\n",
    "        for k, v in i.items():\n",
    "            # How many images to sample?\n",
    "            sample_number = round(int(len(v)*sample_amount))\n",
    "            print(f\"There are {len(v)} total images in '{target_dir+k}' so we're going to copy {sample_number} to the new directory.\")\n",
    "            print(f\"Getting {sample_number} random images for {k}...\")\n",
    "            random_images = random.sample(v, sample_number)\n",
    "\n",
    "            # Make new dir for each key\n",
    "            new_target_dir = new_dir + k\n",
    "            print(f\"Making dir: {new_target_dir}\")\n",
    "            os.makedirs(new_target_dir, exist_ok=True)\n",
    "\n",
    "            # Keep track of images moved\n",
    "            images_moved = []\n",
    "\n",
    "            # Create file paths for original images and new file target\n",
    "            print(f\"Copying images from: {target_dir}\\n\\t\\t to: {new_target_dir}/\\n\")\n",
    "            for file_name in tqdm(random_images):\n",
    "                og_path = target_dir + k + \"/\" + file_name\n",
    "                new_path = new_target_dir + \"/\" + file_name\n",
    "\n",
    "                # Copy images from OG path to new path\n",
    "                shutil.copy2(og_path, new_path)\n",
    "                images_moved.append(new_path)\n",
    "\n",
    "            # Make sure number of images moved is correct\n",
    "            assert len(os.listdir(new_target_dir)) == sample_number\n",
    "            assert len(images_moved) == sample_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efaf4cd-5b8c-4b71-941d-ada3c4522956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito',\n",
       " 'bruschetta',\n",
       " 'caesar_salad',\n",
       " 'cannoli',\n",
       " 'caprese_salad',\n",
       " 'carrot_cake',\n",
       " 'ceviche',\n",
       " 'cheesecake',\n",
       " 'cheese_plate',\n",
       " 'chicken_curry',\n",
       " 'chicken_quesadilla',\n",
       " 'chicken_wings',\n",
       " 'chocolate_cake',\n",
       " 'chocolate_mousse',\n",
       " 'churros',\n",
       " 'clam_chowder',\n",
       " 'club_sandwich',\n",
       " 'crab_cakes',\n",
       " 'creme_brulee',\n",
       " 'croque_madame',\n",
       " 'cup_cakes',\n",
       " 'deviled_eggs',\n",
       " 'donuts',\n",
       " 'dumplings',\n",
       " 'edamame',\n",
       " 'eggs_benedict',\n",
       " 'escargots',\n",
       " 'falafel',\n",
       " 'filet_mignon',\n",
       " 'fish_and_chips',\n",
       " 'foie_gras',\n",
       " 'french_fries',\n",
       " 'french_onion_soup',\n",
       " 'french_toast',\n",
       " 'fried_calamari',\n",
       " 'fried_rice',\n",
       " 'frozen_yogurt',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'greek_salad',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'grilled_salmon',\n",
       " 'guacamole',\n",
       " 'gyoza',\n",
       " 'hamburger',\n",
       " 'hot_and_sour_soup',\n",
       " 'hot_dog',\n",
       " 'huevos_rancheros',\n",
       " 'hummus',\n",
       " 'ice_cream',\n",
       " 'lasagna',\n",
       " 'lobster_bisque',\n",
       " 'lobster_roll_sandwich',\n",
       " 'macaroni_and_cheese',\n",
       " 'macarons',\n",
       " 'miso_soup',\n",
       " 'mussels',\n",
       " 'nachos',\n",
       " 'omelette',\n",
       " 'onion_rings',\n",
       " 'oysters',\n",
       " 'pad_thai',\n",
       " 'paella',\n",
       " 'pancakes',\n",
       " 'panna_cotta',\n",
       " 'peking_duck',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'pork_chop',\n",
       " 'poutine',\n",
       " 'prime_rib',\n",
       " 'pulled_pork_sandwich',\n",
       " 'ramen',\n",
       " 'ravioli',\n",
       " 'red_velvet_cake',\n",
       " 'risotto',\n",
       " 'samosa',\n",
       " 'sashimi',\n",
       " 'scallops',\n",
       " 'seaweed_salad',\n",
       " 'shrimp_and_grits',\n",
       " 'spaghetti_bolognese',\n",
       " 'spaghetti_carbonara',\n",
       " 'spring_rolls',\n",
       " 'steak',\n",
       " 'strawberry_shortcake',\n",
       " 'sushi',\n",
       " 'tacos',\n",
       " 'takoyaki',\n",
       " 'tiramisu',\n",
       " 'tuna_tartare',\n",
       " 'waffles']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all classnames\n",
    "classes = []\n",
    "with open(\"meta/classes.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        classes.append(line.split(\"\\n\")[0]) \n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11809ad4-9c89-4818-8499-3de9d72c055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fde36d-079b-440c-aa8e-91ddbdfb7ee5",
   "metadata": {},
   "source": [
    "## Spliting Whole data in train test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5c2352-f1ae-4286-8071-8e19964de133",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using train labels...\n",
      "Copied 750 images from train dataset apple_pie class...\n",
      "Copied 750 images from train dataset baby_back_ribs class...\n",
      "Copied 750 images from train dataset baklava class...\n",
      "Copied 750 images from train dataset beef_carpaccio class...\n",
      "Copied 750 images from train dataset beef_tartare class...\n",
      "Copied 750 images from train dataset beet_salad class...\n",
      "Copied 750 images from train dataset beignets class...\n",
      "Copied 750 images from train dataset bibimbap class...\n",
      "Copied 750 images from train dataset bread_pudding class...\n",
      "Copied 750 images from train dataset breakfast_burrito class...\n",
      "Copied 750 images from train dataset bruschetta class...\n",
      "Copied 750 images from train dataset caesar_salad class...\n",
      "Copied 750 images from train dataset cannoli class...\n",
      "Copied 750 images from train dataset caprese_salad class...\n",
      "Copied 750 images from train dataset carrot_cake class...\n",
      "Copied 750 images from train dataset ceviche class...\n",
      "Copied 750 images from train dataset cheesecake class...\n",
      "Copied 750 images from train dataset cheese_plate class...\n",
      "Copied 750 images from train dataset chicken_curry class...\n",
      "Copied 750 images from train dataset chicken_quesadilla class...\n",
      "Copied 750 images from train dataset chicken_wings class...\n",
      "Copied 750 images from train dataset chocolate_cake class...\n",
      "Copied 750 images from train dataset chocolate_mousse class...\n",
      "Copied 750 images from train dataset churros class...\n",
      "Copied 750 images from train dataset clam_chowder class...\n",
      "Copied 750 images from train dataset club_sandwich class...\n",
      "Copied 750 images from train dataset crab_cakes class...\n",
      "Copied 750 images from train dataset creme_brulee class...\n",
      "Copied 750 images from train dataset croque_madame class...\n",
      "Copied 750 images from train dataset cup_cakes class...\n",
      "Copied 750 images from train dataset deviled_eggs class...\n",
      "Copied 750 images from train dataset donuts class...\n",
      "Copied 750 images from train dataset dumplings class...\n",
      "Copied 750 images from train dataset edamame class...\n",
      "Copied 750 images from train dataset eggs_benedict class...\n",
      "Copied 750 images from train dataset escargots class...\n",
      "Copied 750 images from train dataset falafel class...\n",
      "Copied 750 images from train dataset filet_mignon class...\n",
      "Copied 750 images from train dataset fish_and_chips class...\n",
      "Copied 750 images from train dataset foie_gras class...\n",
      "Copied 750 images from train dataset french_fries class...\n",
      "Copied 750 images from train dataset french_onion_soup class...\n",
      "Copied 750 images from train dataset french_toast class...\n",
      "Copied 750 images from train dataset fried_calamari class...\n",
      "Copied 750 images from train dataset fried_rice class...\n",
      "Copied 750 images from train dataset frozen_yogurt class...\n",
      "Copied 750 images from train dataset garlic_bread class...\n",
      "Copied 750 images from train dataset gnocchi class...\n",
      "Copied 750 images from train dataset greek_salad class...\n",
      "Copied 750 images from train dataset grilled_cheese_sandwich class...\n",
      "Copied 750 images from train dataset grilled_salmon class...\n",
      "Copied 750 images from train dataset guacamole class...\n",
      "Copied 750 images from train dataset gyoza class...\n",
      "Copied 750 images from train dataset hamburger class...\n",
      "Copied 750 images from train dataset hot_and_sour_soup class...\n",
      "Copied 750 images from train dataset hot_dog class...\n",
      "Copied 750 images from train dataset huevos_rancheros class...\n",
      "Copied 750 images from train dataset hummus class...\n",
      "Copied 750 images from train dataset ice_cream class...\n",
      "Copied 750 images from train dataset lasagna class...\n",
      "Copied 750 images from train dataset lobster_bisque class...\n",
      "Copied 750 images from train dataset lobster_roll_sandwich class...\n",
      "Copied 750 images from train dataset macaroni_and_cheese class...\n",
      "Copied 750 images from train dataset macarons class...\n",
      "Copied 750 images from train dataset miso_soup class...\n",
      "Copied 750 images from train dataset mussels class...\n",
      "Copied 750 images from train dataset nachos class...\n",
      "Copied 750 images from train dataset omelette class...\n",
      "Copied 750 images from train dataset onion_rings class...\n",
      "Copied 750 images from train dataset oysters class...\n",
      "Copied 750 images from train dataset pad_thai class...\n",
      "Copied 750 images from train dataset paella class...\n",
      "Copied 750 images from train dataset pancakes class...\n",
      "Copied 750 images from train dataset panna_cotta class...\n",
      "Copied 750 images from train dataset peking_duck class...\n",
      "Copied 750 images from train dataset pho class...\n",
      "Copied 750 images from train dataset pizza class...\n",
      "Copied 750 images from train dataset pork_chop class...\n",
      "Copied 750 images from train dataset poutine class...\n",
      "Copied 750 images from train dataset prime_rib class...\n",
      "Copied 750 images from train dataset pulled_pork_sandwich class...\n",
      "Copied 750 images from train dataset ramen class...\n",
      "Copied 750 images from train dataset ravioli class...\n",
      "Copied 750 images from train dataset red_velvet_cake class...\n",
      "Copied 750 images from train dataset risotto class...\n",
      "Copied 750 images from train dataset samosa class...\n",
      "Copied 750 images from train dataset sashimi class...\n",
      "Copied 750 images from train dataset scallops class...\n",
      "Copied 750 images from train dataset seaweed_salad class...\n",
      "Copied 750 images from train dataset shrimp_and_grits class...\n",
      "Copied 750 images from train dataset spaghetti_bolognese class...\n",
      "Copied 750 images from train dataset spaghetti_carbonara class...\n",
      "Copied 750 images from train dataset spring_rolls class...\n",
      "Copied 750 images from train dataset steak class...\n",
      "Copied 750 images from train dataset strawberry_shortcake class...\n",
      "Copied 750 images from train dataset sushi class...\n",
      "Copied 750 images from train dataset tacos class...\n",
      "Copied 750 images from train dataset takoyaki class...\n",
      "Copied 750 images from train dataset tiramisu class...\n",
      "Copied 750 images from train dataset tuna_tartare class...\n",
      "Copied 750 images from train dataset waffles class...\n",
      "\n",
      "Using test labels...\n",
      "Copied 250 images from test dataset apple_pie class...\n",
      "Copied 250 images from test dataset baby_back_ribs class...\n",
      "Copied 250 images from test dataset baklava class...\n",
      "Copied 250 images from test dataset beef_carpaccio class...\n",
      "Copied 250 images from test dataset beef_tartare class...\n",
      "Copied 250 images from test dataset beet_salad class...\n",
      "Copied 250 images from test dataset beignets class...\n",
      "Copied 250 images from test dataset bibimbap class...\n",
      "Copied 250 images from test dataset bread_pudding class...\n",
      "Copied 250 images from test dataset breakfast_burrito class...\n",
      "Copied 250 images from test dataset bruschetta class...\n",
      "Copied 250 images from test dataset caesar_salad class...\n",
      "Copied 250 images from test dataset cannoli class...\n",
      "Copied 250 images from test dataset caprese_salad class...\n",
      "Copied 250 images from test dataset carrot_cake class...\n",
      "Copied 250 images from test dataset ceviche class...\n",
      "Copied 250 images from test dataset cheesecake class...\n",
      "Copied 250 images from test dataset cheese_plate class...\n",
      "Copied 250 images from test dataset chicken_curry class...\n",
      "Copied 250 images from test dataset chicken_quesadilla class...\n",
      "Copied 250 images from test dataset chicken_wings class...\n",
      "Copied 250 images from test dataset chocolate_cake class...\n",
      "Copied 250 images from test dataset chocolate_mousse class...\n",
      "Copied 250 images from test dataset churros class...\n",
      "Copied 250 images from test dataset clam_chowder class...\n",
      "Copied 250 images from test dataset club_sandwich class...\n",
      "Copied 250 images from test dataset crab_cakes class...\n",
      "Copied 250 images from test dataset creme_brulee class...\n",
      "Copied 250 images from test dataset croque_madame class...\n",
      "Copied 250 images from test dataset cup_cakes class...\n",
      "Copied 250 images from test dataset deviled_eggs class...\n",
      "Copied 250 images from test dataset donuts class...\n",
      "Copied 250 images from test dataset dumplings class...\n",
      "Copied 250 images from test dataset edamame class...\n",
      "Copied 250 images from test dataset eggs_benedict class...\n",
      "Copied 250 images from test dataset escargots class...\n",
      "Copied 250 images from test dataset falafel class...\n",
      "Copied 250 images from test dataset filet_mignon class...\n",
      "Copied 250 images from test dataset fish_and_chips class...\n",
      "Copied 250 images from test dataset foie_gras class...\n",
      "Copied 250 images from test dataset french_fries class...\n",
      "Copied 250 images from test dataset french_onion_soup class...\n",
      "Copied 250 images from test dataset french_toast class...\n",
      "Copied 250 images from test dataset fried_calamari class...\n",
      "Copied 250 images from test dataset fried_rice class...\n",
      "Copied 250 images from test dataset frozen_yogurt class...\n",
      "Copied 250 images from test dataset garlic_bread class...\n",
      "Copied 250 images from test dataset gnocchi class...\n",
      "Copied 250 images from test dataset greek_salad class...\n",
      "Copied 250 images from test dataset grilled_cheese_sandwich class...\n",
      "Copied 250 images from test dataset grilled_salmon class...\n",
      "Copied 250 images from test dataset guacamole class...\n",
      "Copied 250 images from test dataset gyoza class...\n",
      "Copied 250 images from test dataset hamburger class...\n",
      "Copied 250 images from test dataset hot_and_sour_soup class...\n",
      "Copied 250 images from test dataset hot_dog class...\n",
      "Copied 250 images from test dataset huevos_rancheros class...\n",
      "Copied 250 images from test dataset hummus class...\n",
      "Copied 250 images from test dataset ice_cream class...\n",
      "Copied 250 images from test dataset lasagna class...\n",
      "Copied 250 images from test dataset lobster_bisque class...\n",
      "Copied 250 images from test dataset lobster_roll_sandwich class...\n",
      "Copied 250 images from test dataset macaroni_and_cheese class...\n",
      "Copied 250 images from test dataset macarons class...\n",
      "Copied 250 images from test dataset miso_soup class...\n",
      "Copied 250 images from test dataset mussels class...\n",
      "Copied 250 images from test dataset nachos class...\n",
      "Copied 250 images from test dataset omelette class...\n",
      "Copied 250 images from test dataset onion_rings class...\n",
      "Copied 250 images from test dataset oysters class...\n",
      "Copied 250 images from test dataset pad_thai class...\n",
      "Copied 250 images from test dataset paella class...\n",
      "Copied 250 images from test dataset pancakes class...\n",
      "Copied 250 images from test dataset panna_cotta class...\n",
      "Copied 250 images from test dataset peking_duck class...\n",
      "Copied 250 images from test dataset pho class...\n",
      "Copied 250 images from test dataset pizza class...\n",
      "Copied 250 images from test dataset pork_chop class...\n",
      "Copied 250 images from test dataset poutine class...\n",
      "Copied 250 images from test dataset prime_rib class...\n",
      "Copied 250 images from test dataset pulled_pork_sandwich class...\n",
      "Copied 250 images from test dataset ramen class...\n",
      "Copied 250 images from test dataset ravioli class...\n",
      "Copied 250 images from test dataset red_velvet_cake class...\n",
      "Copied 250 images from test dataset risotto class...\n",
      "Copied 250 images from test dataset samosa class...\n",
      "Copied 250 images from test dataset sashimi class...\n",
      "Copied 250 images from test dataset scallops class...\n",
      "Copied 250 images from test dataset seaweed_salad class...\n",
      "Copied 250 images from test dataset shrimp_and_grits class...\n",
      "Copied 250 images from test dataset spaghetti_bolognese class...\n",
      "Copied 250 images from test dataset spaghetti_carbonara class...\n",
      "Copied 250 images from test dataset spring_rolls class...\n",
      "Copied 250 images from test dataset steak class...\n",
      "Copied 250 images from test dataset strawberry_shortcake class...\n",
      "Copied 250 images from test dataset sushi class...\n",
      "Copied 250 images from test dataset tacos class...\n",
      "Copied 250 images from test dataset takoyaki class...\n",
      "Copied 250 images from test dataset tiramisu class...\n",
      "Copied 250 images from test dataset tuna_tartare class...\n",
      "Copied 250 images from test dataset waffles class...\n"
     ]
    }
   ],
   "source": [
    "parent_folder = \"data\"\n",
    "new_subset = \"all_food_classes\"\n",
    "datasets = [\"train\", \"test\"]\n",
    "\n",
    "# Copy training/test images\n",
    "for i in datasets:\n",
    "    copy_images(parent_folder=parent_folder,\n",
    "                new_subset=new_subset,\n",
    "                dataset=i,\n",
    "                target_labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951d83e-e8f4-4058-b4a6-c2a01e199412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
